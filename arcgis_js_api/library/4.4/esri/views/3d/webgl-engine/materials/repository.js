// All material copyright ESRI, All Rights Reserved, unless otherwise specified.
// See https://js.arcgis.com/4.4/esri/copyright.txt for details.
//>>built
require({cache:{"url:esri/views/3d/webgl-engine/materials/internal/util.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\r\n\r\n\x3csnippets\x3e\r\n\r\n\x3csnippet name\x3d"alignToPixelCenter"\x3e\x3c![CDATA[\r\n  vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {\r\n    // From clip space to (0 : 1), bias towards right pixel edge\r\n    vec2 xy \x3d vec2(.500123) + .5 * clipCoord.xy / clipCoord.w;\r\n\r\n    // Size of a pixel in range (0 : 1)\r\n    vec2 pixelSz \x3d vec2(1.0) / widthHeight;\r\n\r\n    // Round to nearest pixel center\r\n    vec2 ij \x3d (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;\r\n\r\n    // Convert back to clip space\r\n    vec2 result \x3d (ij * 2.0 - vec2(1.0)) * clipCoord.w;\r\n\r\n    return vec4(result, clipCoord.zw);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"alignToPixelOrigin"\x3e\x3c![CDATA[\r\n  vec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {\r\n    // From clip space to (0 : 1),\r\n    vec2 xy \x3d vec2(.5) + .5 * clipCoord.xy / clipCoord.w;\r\n\r\n    // Size of a pixel in range (0 : 1)\r\n    vec2 pixelSz \x3d vec2(1.0) / widthHeight;\r\n\r\n    // Round to nearest pixel border, (0 : 1)\r\n    vec2 ij \x3d floor((xy + .5 * pixelSz) * widthHeight) * pixelSz;\r\n\r\n    // Convert back to clip space\r\n    vec2 result \x3d (ij * 2.0 - vec2(1.0)) * clipCoord.w;\r\n\r\n    return vec4(result, clipCoord.zw);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"float2rgba"\x3e\x3c![CDATA[\r\n\tvec4 float2rgba(const in float v) {\r\n\t\tvec4 enc \x3d vec4(1.0, 255.0, 65025.0, 16581375.0) * v;\r\n\t\tenc \x3d fract(enc);\r\n\t\tenc -\x3d enc.yzww * vec4(1.0/255.0, 1.0/255.0, 1.0/255.0, 0.0);\r\n\t\treturn enc;\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"rgba2float"\x3e\x3c![CDATA[\r\n\tfloat rgba2float(vec4 rgba) {\r\n\t\treturn dot(rgba, vec4(1.0, 1.0/255.0, 1.0/65025.0, 1.0/16581375.0));\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"calcFragDepth"\x3e\x3c![CDATA[\r\n\t#extension GL_OES_standard_derivatives : enable\r\n\r\n\tfloat calcFragDepth(const in float depth) {\r\n\t\t//calc polygon offset\r\n\t\tconst float SLOPE_SCALE \x3d 2.0;\r\n\t\tconst float BIAS \x3d 2.0 * .000015259;\t\t// 1 / (2^16 - 1)\r\n\t\tfloat m \x3d max(abs(dFdx(depth)), abs(dFdy(depth)));\r\n\t\tfloat result \x3d depth + SLOPE_SCALE * m + BIAS;\r\n\t\treturn clamp(result, .0, .999999);\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"evalShadow"\x3e\x3c![CDATA[\r\n\t$rgba2float\r\n\r\n\t// "matrix" parameter used to have const qualifier as well, but IE11 couldn\'t deal with it at time of writing.\r\n\t// once IE11 is fine with it, const should probably be re-introduced\r\n\tfloat evalShadow(const in vec3 vpos, const in float depth, const in sampler2D depthTex, const int num, const in vec4 distance, in mat4 matrix[4], const in float halfPxSz) {\r\n\t\t//choose correct cascade\r\n\t\tint i \x3d depth \x3c distance[1] ? 0 : depth \x3c distance[2] ? 1 : depth \x3c distance[3] ? 2 : 3;\r\n\r\n\t\tif (i \x3e\x3d num) return .0;\r\n\r\n\t\tmat4 mat \x3d i \x3d\x3d 0 ? matrix[0] : i \x3d\x3d 1 ? matrix[1] : i \x3d\x3d 2 ? matrix[2] : matrix[3];\r\n\r\n\t\tvec4 lv \x3d mat * vec4(vpos, 1.0);\r\n\t\tlv.xy /\x3d lv.w;\r\n\r\n\t\t//vertex completely outside? -\x3e no shadow\r\n\t\tvec3 lvpos \x3d .5 * lv.xyz + vec3(.5);\r\n\t\tif (lvpos.z \x3e\x3d 1.0) return .0;\r\n\t\tif (lvpos.x \x3c .0 || lvpos.x \x3e 1.0 || lvpos.y \x3c .0 || lvpos.y \x3e 1.0) return .0;\r\n\r\n\t\t//calc coord in cascade texture\r\n\t\tvec2 uv \x3d vec2(float(i - 2 * (i / 2)) *.5, float(i / 2) * .5) + .5 * lvpos.xy;\r\n\r\n\t\tfloat texSize \x3d .5 / halfPxSz;\r\n\r\n\t\t//filter, offset by half pixels\r\n\t\tvec2 st \x3d fract((vec2(halfPxSz) + uv) * texSize);\r\n\r\n\t\tfloat s00 \x3d rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, -halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n\t\tfloat s10 \x3d rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, -halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n\t\tfloat s11 \x3d rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n\t\tfloat s01 \x3d rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, halfPxSz))) \x3c lvpos.z ? 1.0 : .0;\r\n\r\n\t\treturn mix(mix(s00, s10, st.x), mix(s01, s11, st.x), st.y);\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\r\n\x3c!--\r\n\tScene Lighting Definitions:\r\n\t\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\x3d\r\n\r\n\tdefines:\r\n\t\t- SH_ORDER: 1|2|3\r\n\tinput:\r\n\t\t- normal: vec3\r\n\t\t- albedo: vec3\r\n\t  - shadow: float\r\n\t\t- ssao: float\r\n\treturn:\r\n\t  - color: vec3\r\n--\x3e\r\n\x3csnippet name\x3d"sceneLightingDefinitions"\x3e\x3c![CDATA[\r\n\t$viewingMode\r\n\r\n\t// main light\r\n\t/////////////////////////////////////////\r\n\tuniform vec3 lightingMainDirection;\r\n\tuniform vec3 lightingMainIntensity;\r\n\r\n\t// ambient lighting\r\n\t/////////////////////////////////////////\r\n\t#ifndef SH_ORDER\r\n\t\t#define SH_ORDER 2\r\n\t#endif\r\n\r\n\t#if SH_ORDER \x3d\x3d 0\r\n\t\tuniform vec3 lightingAmbientSH0;\r\n\t#elif SH_ORDER \x3d\x3d 1\r\n\t\tuniform vec4 lightingAmbientSH_R;\r\n\t\tuniform vec4 lightingAmbientSH_G;\r\n\t\tuniform vec4 lightingAmbientSH_B;\r\n\t#elif SH_ORDER \x3d\x3d 2\r\n\t\tuniform vec3 lightingAmbientSH0;\r\n\t\tuniform vec4 lightingAmbientSH_R1;\r\n\t\tuniform vec4 lightingAmbientSH_G1;\r\n\t\tuniform vec4 lightingAmbientSH_B1;\r\n\t\tuniform vec4 lightingAmbientSH_R2;\r\n\t\tuniform vec4 lightingAmbientSH_G2;\r\n\t\tuniform vec4 lightingAmbientSH_B2;\r\n\t#endif\r\n\r\n\t// special tweaking\r\n\t//////////////////////////////////////////\r\n\t\tuniform float lightingFixedFactor;\r\n\t\tuniform float lightingGlobalFactor;\r\n\r\n\t\tuniform float ambientBoostFactor;\r\n\r\n\t// evaluation\r\n\t//////////////////////////////////////////\r\n\r\n\tvec3 evaluateSceneLighting(vec3 normal, vec3 albedo, float shadow, float ssao, vec3 additionalLight) {\r\n\t\t// evaluate the main light\r\n\t\tfloat dotVal \x3d mix(clamp(-dot(normal, lightingMainDirection), 0.0, 1.0), 1.0, lightingFixedFactor);\r\n\t\tvec3 mainLight \x3d (1.0 - shadow) * lightingMainIntensity * dotVal;\r\n\r\n\t\t// evaluate the sh ambient light\r\n\t\t#if SH_ORDER \x3d\x3d 0\r\n\t\t\tvec3 ambientLight \x3d 0.282095 * lightingAmbientSH0;\r\n\t\t#elif SH_ORDER \x3d\x3d 1\r\n\t\t\tvec4 sh0 \x3d vec4(\r\n\t\t\t\t0.282095,\r\n\t\t\t\t0.488603 * normal.x,\r\n\t\t\t\t0.488603 * normal.z,\r\n\t\t\t\t0.488603 * normal.y\r\n\t\t\t);\r\n\t\t\tvec3 ambientLight \x3d vec3(\r\n\t\t\t\tdot(lightingAmbientSH_R, sh0),\r\n\t\t\t\tdot(lightingAmbientSH_G, sh0),\r\n\t\t\t\tdot(lightingAmbientSH_B, sh0)\r\n\t\t\t);\r\n\t\t#elif SH_ORDER \x3d\x3d 2\r\n\t\t\tvec3 ambientLight \x3d 0.282095 * lightingAmbientSH0;\r\n\r\n\t\t\tvec4 sh1 \x3d vec4(\r\n\t\t\t\t0.488603 * normal.x,\r\n\t\t\t\t0.488603 * normal.z,\r\n\t\t\t\t0.488603 * normal.y,\r\n\t\t\t\t1.092548 * normal.x * normal.y\r\n\t\t\t);\r\n\t\t\tvec4 sh2 \x3d vec4(\r\n\t\t\t\t1.092548 * normal.y * normal.z,\r\n\t\t\t\t0.315392 * (3.0 * normal.z * normal.z - 1.0),\r\n\t\t\t\t1.092548 * normal.x * normal.z,\r\n\t\t\t\t0.546274 * (normal.x * normal.x - normal.y * normal.y)\r\n\t\t\t);\r\n\t\t\tambientLight +\x3d vec3(\r\n\t\t\t\tdot(lightingAmbientSH_R1, sh1),\r\n\t\t\t\tdot(lightingAmbientSH_G1, sh1),\r\n\t\t\t\tdot(lightingAmbientSH_B1, sh1)\r\n\t\t\t);\r\n\t\t\tambientLight +\x3d vec3(\r\n\t\t\t\tdot(lightingAmbientSH_R2, sh2),\r\n\t\t\t\tdot(lightingAmbientSH_G2, sh2),\r\n\t\t\t\tdot(lightingAmbientSH_B2, sh2)\r\n\t\t\t);\r\n\t\t#endif\r\n\t\tambientLight *\x3d (1.0 - ssao);\r\n\r\n\t\t// inverse gamma correction on the albedo color\r\n\t\tfloat gamma \x3d 2.1;\r\n\t\tvec3 albedoGammaC \x3d pow(albedo, vec3(gamma));\r\n\r\n\t\t// physically correct BRDF normalizes by PI\r\n\t\tconst float PI \x3d 3.14159;\r\n\t\tvec3 totalLight \x3d mainLight + ambientLight + additionalLight;\r\n\t\ttotalLight \x3d min(totalLight, vec3(PI, PI, PI));\r\n\t\tvec3 outColor \x3d vec3((albedoGammaC / PI) * (totalLight));\r\n\r\n\t\t// apply gamma correction to the computed color\r\n\t\toutColor \x3d pow(outColor, vec3(1.0/gamma));\r\n\r\n\t\treturn outColor;\r\n\t}\r\n\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"sceneLightingAdditionalLightGlobal"\x3e\x3c![CDATA[\r\n\t// heuristic lighting model originally used in the terrain shading\r\n\t// now used to generated additional ambient light\r\n\t#ifdef VIEWING_MODE_GLOBAL\r\n\t\tfloat vndl \x3d -dot(normalize(vpos + localOrigin), lightingMainDirection);\r\n\t#else\r\n\t\tfloat vndl \x3d -dot(vec3(0,0,1), lightingMainDirection);\r\n\t#endif\r\n\tfloat additionalAmbientScale \x3d smoothstep(0.0, 1.0, clamp(vndl*2.5, 0.0, 1.0));\r\n\tvec3 additionalLight \x3d ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"normal2envTC"\x3e\x3c![CDATA[\r\n\tvec2 normal2envTC(vec3 normal) {\r\n\t\tfloat v \x3d .5 + .5 * asin(normal.y) * 0.63661977;\r\n\t\tfloat u \x3d .5 - .5 * atan(normal.z, normal.x) * 0.31830988;\r\n\t\treturn vec2(u, v);\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vertexShaderShowDepth"\x3e\x3c![CDATA[\r\n  $vsprecisionf\r\n\r\n\tuniform mat4 proj;\r\n\tattribute vec2 $position;\r\n\tattribute vec2 $uv0;\r\n\tvarying vec2 vtc;\r\n\r\n\tvoid main(void) {\r\n\t\tgl_Position \x3d proj * vec4($position.x, $position.y, .0, 1.0);\r\n\t\tvtc \x3d $uv0;\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\t\x3csnippet name\x3d"fragmentShaderShowDepth"\x3e\x3c![CDATA[\r\n\t$fsprecisionf\r\n\r\n\tuniform sampler2D depthTex;\r\n\tvarying vec2 vtc;\r\n\t$rgba2float\r\n\tvoid main() {\r\n\t//\tgl_FragColor \x3d vec4(vec3(texture2D(depthTex, vtc).a), 1.0);\r\n\t\tgl_FragColor \x3d vec4(rgba2float(texture2D(depthTex, vtc)));\r\n\t//\tgl_FragColor \x3d texture2D(depthTex, vtc);\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vsUVQuad"\x3e\x3c![CDATA[\r\n  $vsprecisionf\r\n\r\n\tattribute vec2 $position;\r\n\tvarying vec2 uv;\r\n\r\n\tvoid main(void) {\r\n\t\tgl_Position \x3d vec4($position.x, $position.y, .0, 1.0);\r\n\t\tuv \x3d $position * .5 + vec2(.5);\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"toScreenCoords"\x3e\x3c![CDATA[\r\n\tvec4 toScreenCoords(vec3 vertex) {\r\n\t\tvec4 vClipSpace \x3d proj * view * vec4((model * vec4(vertex, 1.0)).xyz, 1.0);\r\n\t\tvClipSpace.xy *\x3d screenSize;\r\n\t\treturn vClipSpace/abs(vClipSpace.w);\r\n\t}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vvUniforms"\x3e\x3c![CDATA[\r\n#if defined(VV_SIZE)\r\n\t#define VV_CUSTOM_MODEL_MATRIX\r\n#endif\r\n\r\n#if defined(VV_SIZE)\r\n\tuniform vec3 vvSizeMinSize;\r\n\tuniform vec3 vvSizeMaxSize;\r\n\tuniform vec3 vvSizeOffset;\r\n\tuniform vec3 vvSizeFactor;\r\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\r\n\tuniform vec3 vvSizeValue;\r\n#endif\r\n\r\n#ifdef VV_CUSTOM_MODEL_MATRIX\r\n\tuniform mat3 vvSymbolRotation;\r\n#endif\r\n\r\n#ifdef VV_CUSTOM_MODEL_MATRIX\r\n\tuniform vec3 vvSymbolAnchor;\r\n#endif\r\n\r\n#ifdef VV_COLOR\r\n\t#define VV_COLOR_N 8\r\n\tuniform float vvColorValues[VV_COLOR_N];\r\n\tuniform vec4 vvColorColors[VV_COLOR_N];\r\n#endif\r\n\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"vvFunctions"\x3e\x3c![CDATA[\r\n// Evaluation of size\r\n#if defined(VV_SIZE)\r\n\tvec3 vvGetScale(vec4 featureAttribute) {\r\n\t\treturn clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize);\r\n\t}\r\n#elif defined(VV_CUSTOM_MODEL_MATRIX)\r\n\tvec3 vvGetScale(vec4 featureAttribute) {\r\n\t\treturn vvSizeValue;\r\n\t}\r\n#endif\r\n\r\n// Applying the model matrix\r\n#ifdef VV_CUSTOM_MODEL_MATRIX\r\n\tvec4 vvTransformPosition(vec3 position, vec4 featureAttribute) {\r\n\t\treturn vec4(vvSymbolRotation * (vvGetScale(featureAttribute) * (position + vvSymbolAnchor)), 1.0);\r\n\t}\r\n\r\n\tvec4 vvTransformNormal(vec3 normal, vec4 featureAttribute) {\r\n\t\t// Normal transform is the inverse transpose of model transform\r\n\t\treturn vec4(vvSymbolRotation * normal / vvGetScale(featureAttribute), 1.0);\r\n\t}\r\n#endif\r\n\r\n#ifdef VV_COLOR\r\n\tvec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {\r\n\t\tfloat value \x3d featureAttribute.y;\r\n\t\tif (value \x3c\x3d values[0]) {\r\n\t\t\treturn colors[0];\r\n\t\t}\r\n\r\n\t\tfor (int i \x3d 1; i \x3c VV_COLOR_N; ++i) {\r\n\t\t\tif (values[i] \x3e\x3d value) {\r\n\t\t\t\tfloat f \x3d (value - values[i-1]) / (values[i] - values[i-1]);\r\n\t\t\t\treturn mix(colors[i-1], colors[i], f);\r\n\t\t\t}\r\n\t\t}\r\n\r\n\t\treturn colors[VV_COLOR_N - 1];\r\n\t}\r\n#endif\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"rgb2hsv"\x3e\x3c![CDATA[\r\nvec3 rgb2hsv(vec3 c)\r\n{\r\n\tvec4 K \x3d vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);\r\n\tvec4 p \x3d mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));\r\n\tvec4 q \x3d mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));\r\n\r\n\tfloat d \x3d q.x - min(q.w, q.y);\r\n\tfloat e \x3d 1.0e-10;\r\n\treturn vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);\r\n}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"hsv2rgb"\x3e\x3c![CDATA[\r\nvec3 hsv2rgb(vec3 c)\r\n{\r\n\tvec4 K \x3d vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);\r\n\tvec3 p \x3d abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\r\n\treturn c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\r\n}\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"colorMixMode"\x3e\x3c![CDATA[\r\n$rgb2hsv\r\n$hsv2rgb\r\n\r\n\r\n/*\r\n * The color mix modes are encoded in the symbol color as follows:\r\n *  - Fully transparent symbols are represented with alpha 0 for\r\n *    all color mix modes (except ignore).\r\n *  - color mix mode ignore is encoded as multiply with white\r\n *  - the other 3 color mix modes (tint, replace, multiply) are\r\n *    equally distributed on the remaining 255 alpha values, which\r\n *    gives us 85 possible alpha values\r\n *\r\n * alpha             0 : fully transparent\r\n * alpha in [  1 -  85]: tint\r\n * alpha in [ 86 - 170]: replace\r\n * alpha in [171 - 255]: multiply\r\n */\r\nvec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {\r\n  float symbolAlpha \x3d 0.0;\r\n\r\n  const float maxTint \x3d 85.0;\r\n  const float maxReplace \x3d 170.0;\r\n  const float scaleAlpha \x3d 3.0;\r\n\r\n  if (symbolColor.a \x3d\x3d 0.0) {\r\n    colorMixMode \x3d 1; // fully transparent -\x3e multiply\r\n    symbolAlpha \x3d 0.0;\r\n  }\r\n  else if (symbolColor.a \x3c\x3d maxTint) {\r\n    colorMixMode \x3d 0; // tint\r\n    symbolAlpha \x3d scaleAlpha * symbolColor.a;\r\n  }\r\n  else if (symbolColor.a \x3c\x3d maxReplace) {\r\n    colorMixMode \x3d 3; // replace\r\n    symbolAlpha \x3d scaleAlpha * (symbolColor.a - maxTint);\r\n  }\r\n  else {\r\n    colorMixMode \x3d 1;  // multiply\r\n    symbolAlpha \x3d scaleAlpha * (symbolColor.a - maxReplace);\r\n  }\r\n\r\n  return vec4(symbolColor.rgb, symbolAlpha);\r\n}\r\n\r\nvec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {\r\n  if (mode \x3d\x3d 1 /* multiply */) {\r\n    return internalColor * textureColor * externalColor;\r\n  }\r\n  else if (mode \x3d\x3d 2 /* ignore */ ) {\r\n    return internalColor * textureColor;\r\n  }\r\n  else if (mode \x3d\x3d 3 /* replace */ ) {\r\n    return externalColor;\r\n  }\r\n  else {\r\n    // tint (or something invalid)\r\n    vec3 hsvIn \x3d rgb2hsv(internalColor * textureColor);\r\n    vec3 hsvTint \x3d rgb2hsv(externalColor);\r\n    vec3 hsvOut \x3d vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);\r\n    return hsv2rgb(hsvOut);\r\n  }\r\n}\r\n\r\nfloat mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {\r\n  if (mode \x3d\x3d 2 /* ignore */ ) {\r\n    return internalOpacity * textureOpacity;\r\n  }\r\n  else if (mode \x3d\x3d 3 /* replace */ ) {\r\n    return externalOpacity;\r\n  }\r\n  else {\r\n    // multiply or tint (or something invalid)\r\n    return internalOpacity * textureOpacity * externalOpacity;\r\n  }\r\n}\r\n\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"highlightWrite"\x3e\x3c![CDATA[\r\n  // the following uniforms are common to all highlight shaders:\r\n  // uniform sampler2D depthTex\r\n  // uniform vec4 highlightViewportPixelSz\r\n  float sceneDepth \x3d texture2D(depthTex, (gl_FragCoord.xy - highlightViewportPixelSz.xy) * highlightViewportPixelSz.zw).r;\r\n  if (gl_FragCoord.z \x3e sceneDepth + 5e-6) {\r\n    gl_FragColor \x3d vec4(1.0, 1.0, 0.0, 1.0);\r\n  }\r\n  else {\r\n    gl_FragColor \x3d vec4(1.0, 0.0, 1.0, 1.0);\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"screenSizePerspective"\x3e\x3c![CDATA[\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n\r\n// These could be functions, but I wanted to make sure that they are inlined. Additionally,\r\n// as macros, applying the scale works also for different types (float, vec2, etc).\r\n// Note that the implementation here should be kept in sync with the corresponding\r\n// CPU implementation (used for hitTest etc) in screenSizePerspectiveUtils.ts\r\n\r\n// Transform the input minimum size (factor.z) so that, when comparing to it, we are\r\n// excluding the \'padding\' size (factor.w).\r\n#define screenSizePerspectiveMinSize(/* float */ size, /* vec4 */ factor) (factor.z * (1.0 + 2.0 * factor.w  / size))\r\n\r\n#define screenSizePerspectiveFactor(/* float */ absCosAngle) (absCosAngle * absCosAngle * absCosAngle)\r\n\r\n#define screenSizePerspectiveScaleFactor(/* float */ absCosAngle, /* float */ distanceToCamera, /* vec4 */ params) vec4(min(params.x / (distanceToCamera - params.y), 1.0), screenSizePerspectiveFactor(absCosAngle), params.z, params.w)\r\n\r\n// Factor is computed from screenSizePerspectiveScaleFactor\r\n#define applyScreenSizePerspectiveScaleFactorFloat(/* float */ size, /* vec4 */ factor) max(mix(size * factor.x, size, factor.y), screenSizePerspectiveMinSize(size, factor))\r\n#define screenSizePerspectiveScaleFloat(/* float */ size, /* float */ absCosAngle, /* float */ distanceToCamera, /* vec4 */ params) applyScreenSizePerspectiveScaleFactorFloat(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params))\r\n\r\n#define applyScreenSizePerspectiveScaleFactorVec2(/* vec2 */ size, /* vec4 */ factor) mix(size * clamp(factor.x, screenSizePerspectiveMinSize(size.y, factor) / size.y, 1.0), size, factor.y)\r\n#define screenSizePerspectiveScaleVec2(/* vec2 */ size, /* float */ absCosAngle, /* float */ distanceToCamera, /* vec4 */ params) applyScreenSizePerspectiveScaleFactorVec2(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params))\r\n\r\n#endif\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"selectShadingNormal"\x3e\x3c![CDATA[\r\n\t#ifdef GROUND_NORMAL_SHADING\r\n\t\t#ifdef VIEWING_MODE_GLOBAL\r\n\t\t\tvec3 shadingNormal \x3d normalize(vpos + localOrigin);\r\n\t\t#else\r\n\t\t\tvec3 shadingNormal \x3d vec3(0,0,1);\r\n\t\t#endif\r\n\t#else\r\n\t\tvec3 shadingNormal \x3d normal;\r\n\t#endif\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3c/snippets\x3e\r\n',
"url:esri/views/3d/webgl-engine/materials/internal/hud.xml":'\x3c?xml version\x3d"1.0" encoding\x3d"UTF-8"?\x3e\r\n\r\n\x3csnippets\x3e\r\n\r\n\x3csnippet name\x3d"commonAttributesAndUniformsHUD"\x3e\x3c![CDATA[\r\n  attribute vec3 $position;\r\n  attribute vec3 $normal;\r\n  attribute vec4 $auxpos1;\r\n\r\n  uniform mat4 proj;\r\n\r\n  uniform mat4 view;\r\n  uniform mat4 viewNormal;\r\n\r\n  uniform mat4 model;\r\n  uniform mat4 modelNormal;\r\n\r\n  uniform vec4 viewport;\r\n\r\n  uniform vec3 camPos;\r\n\r\n  uniform float polygonOffset;\r\n  uniform float cameraGroundRelative;\r\n\r\n#ifdef VERTICAL_OFFSET\r\n\r\n  // [ screenLength, distanceFactor, minWorldLength, maxWorldLength ]\r\n  uniform vec4 verticalOffset;\r\n\r\n#endif\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n\r\n  // [ divisor, offset, minPixelSize, paddingPixels ]\r\n  uniform vec4 screenSizePerspectiveAlignment;\r\n\r\n#endif\r\n\r\n  uniform sampler2D hudVisibilityTexture;\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3csnippet name\x3d"projectPositionHUD"\x3e\x3c![CDATA[\r\n  $screenSizePerspective\r\n\r\n  // Corresponds to cos(10 deg), used to compare against dot product of two vectors\r\n  const float SMALL_OFFSET_ANGLE \x3d 0.984807753012208;\r\n\r\n  struct ProjectHUDAux {\r\n    vec3 posModel;\r\n    vec3 posView;\r\n    vec3 vnormal;\r\n\r\n    float distanceToCamera;\r\n    float absCosAngle;\r\n  };\r\n\r\n\r\n  /**\r\n   * Apply the simulated polygon offset for HUD objects that improves\r\n   * issues with Z-fighting.\r\n   *\r\n   * @param posView {vec3} (inout) the position in view space. Will be modified in place.\r\n   * @param pointGroundDistance {float} the distance from the point geometry to the ground surface.\r\n   * @param absCosAngle {float} the absolute cosine of the angle between the world-up at the point geometry\r\n   *   and the view direction.\r\n   *\r\n   * Dependencies:\r\n   *\r\n   *   Attributes:\r\n   *     - auxpos1: contains centerOffset and pointGroundDistance\r\n   *\r\n   *   Uniforms:\r\n   *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\r\n   *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\r\n   *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\r\n   *         reduced flickering.\r\n   *     - viewport: the viewport [x, y, width, height]\r\n   */\r\n  float applyHUDViewDependentPolygonOffset(float pointGroundDistance, float absCosAngle, inout vec3 posView) {\r\n    float pointGroundSign \x3d sign(pointGroundDistance);\r\n\r\n    if (pointGroundSign \x3d\x3d 0.0) {\r\n      pointGroundSign \x3d 1.0;\r\n    }\r\n\r\n    // cameraGroundRelative is -1 if camera is below ground, 1 if above ground\r\n    // groundRelative is 1 if both camera and symbol are on the same side of the ground, -1 otherwise\r\n    float groundRelative \x3d cameraGroundRelative * pointGroundSign;\r\n\r\n    // view angle dependent part of polygon offset emulation\r\n    // we take the absolute value because the sign that is dropped is\r\n    // instead introduced using the ground-relative position of the symbol and the camera\r\n    if (polygonOffset \x3e .0) {\r\n      float cosAlpha \x3d clamp(absCosAngle, 0.01, 1.0);\r\n\r\n      float tanAlpha \x3d sqrt(1.0 - cosAlpha * cosAlpha) / cosAlpha;\r\n      float factor \x3d (1.0 - tanAlpha / viewport[2]);\r\n\r\n      // same side of the terrain\r\n      if (groundRelative \x3e 0.0) {\r\n        posView *\x3d factor;\r\n      }\r\n      // opposite sides of the terrain\r\n      else {\r\n        posView /\x3d factor;\r\n      }\r\n    }\r\n\r\n    return groundRelative;\r\n  }\r\n\r\n  /**\r\n   * Project the 3d position of a HUD object from world space to clip space. In addition\r\n   * to standard model view projection, it also emulates a polygon offset to\r\n   * help with points above/below ground and icon flickering. The resulting location\r\n   * is the anchor of the HUD object, i.e. the position that is used also for testing\r\n   * visibility of the HUD object. Note that the returned projected position is not\r\n   * aligned to a pixel center or border, it is up to the caller to align if necessary.\r\n   *\r\n   * Dependencies:\r\n   *\r\n   *   Attributes:\r\n   *     - position: contains the point world position\r\n   *     - normal: contains the world normal pointing up at the point\r\n   *     - auxpos1: contains centerOffset and pointGroundDistance\r\n   *\r\n   *   Uniforms:\r\n   *     - model: the object -\x3e world transformation matrix\r\n   *     - modelNormal: the object -\x3e world normal transformation matrix (inv transp of model)\r\n   *     - view: the world -\x3e view transformation matrix\r\n   *     - viewNormal: the world -\x3e view normal transformation matrix (inv transp of view)\r\n   *     - proj: the view -\x3e clip projection matrix\r\n   *     - verticalOffset: a vec4 containing:\r\n   *         - the screen height of the vertical offset\r\n   *         - the screen height of the vertical offset as a fraction of camera distance.\r\n   *         - the minimum world size vertical offset.\r\n   *         - the maximum world size vertical offset.\r\n   *       This will do a screen sized offset of the point along its normal (used for line callouts)\r\n   *     - screenSizePerspectiveAlignment: a vec3 containing\r\n   *         - the view distance dependent divisor\r\n   *         - the view distance dependent offset\r\n   *         - the minimum pixel size\r\n   *         - the amount of padding in pixels around the region to be scaled (not used for alignment)\r\n   *     - cameraGroundRelative: indicates whether camera is above (1) or below (-1) ground.\r\n   *         This is used for emulated polygon offset for improved visibility of points sitting on the surface.\r\n   *     - polygonOffset: a constant polygon offset to bring the point closer to the viewer for\r\n   *         reduced flickering.\r\n   *     - camPos: the position of the camera in world space\r\n   *     - viewport: the viewport [x, y, width, height]\r\n   */\r\n  vec4 projectPositionHUD(out ProjectHUDAux aux) {\r\n    // centerOffset is in view space and is used to implement world size offsetting\r\n    // of labels with respect to objects. It also pulls the label towards the viewer\r\n    // so that the label is visible in front of the object.\r\n    vec3 centerOffset \x3d $auxpos1.xyz;\r\n\r\n    // The pointGroundDistance is the distance of the geometry to the ground and is\r\n    // negative if the point is below the ground, or positive if the point is above\r\n    // ground.\r\n    float pointGroundDistance \x3d $auxpos1.w;\r\n\r\n    aux.posModel \x3d (model * vec4($position, 1.0)).xyz;\r\n    aux.posView \x3d (view * vec4(aux.posModel, 1.0)).xyz;\r\n    aux.vnormal \x3d (modelNormal * vec4($normal, 1.0)).xyz;\r\n\r\n    // Screen sized offset in world space, used for example for line callouts\r\n    // Note: keep this implementation in sync with the CPU implementation, see\r\n    //   - MaterialUtil.verticalOffsetAtDistance\r\n    //   - HUDMaterial.applyVerticalOffsetTransformation\r\n\r\n    aux.distanceToCamera \x3d length(aux.posView);\r\n\r\n    vec3 viewDirObjSpace \x3d normalize(camPos - aux.posModel);\r\n    float cosAngle \x3d dot(aux.vnormal, viewDirObjSpace);\r\n\r\n    aux.absCosAngle \x3d abs(cosAngle);\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n\r\n#if defined(VERTICAL_OFFSET) || defined(CENTER_OFFSET_UNITS_SCREEN)\r\n    vec4 perspectiveFactor \x3d screenSizePerspectiveScaleFactor(aux.absCosAngle, aux.distanceToCamera, screenSizePerspectiveAlignment);\r\n#endif\r\n\r\n#endif\r\n\r\n#ifdef VERTICAL_OFFSET\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n    float verticalOffsetScreenHeight \x3d applyScreenSizePerspectiveScaleFactorFloat(verticalOffset.x, perspectiveFactor);\r\n#else\r\n    float verticalOffsetScreenHeight \x3d verticalOffset.x;\r\n#endif\r\n\r\n    float worldOffset \x3d clamp(verticalOffsetScreenHeight * verticalOffset.y * aux.distanceToCamera, verticalOffset.z, verticalOffset.w);\r\n    vec3 modelOffset \x3d aux.vnormal * worldOffset;\r\n\r\n    aux.posModel +\x3d modelOffset;\r\n\r\n    vec3 viewOffset \x3d (viewNormal * vec4(modelOffset, 1.0)).xyz;\r\n    aux.posView +\x3d viewOffset;\r\n\r\n    // Since we elevate the object, we need to take that into account\r\n    // in the distance to ground\r\n    pointGroundDistance +\x3d worldOffset;\r\n\r\n#endif\r\n\r\n    float groundRelative \x3d applyHUDViewDependentPolygonOffset(pointGroundDistance, aux.absCosAngle, aux.posView);\r\n\r\n#ifndef CENTER_OFFSET_UNITS_SCREEN\r\n    // Apply x/y in view space, but z in screen space (i.e. along posView direction)\r\n    aux.posView +\x3d vec3(centerOffset.x, centerOffset.y, 0);\r\n\r\n    // Same material all have same z !\x3d 0.0 condition so should not lead to\r\n    // branch fragmentation and will save a normalization if it\'s not needed\r\n    if (centerOffset.z !\x3d 0.0) {\r\n      aux.posView -\x3d normalize(aux.posView) * centerOffset.z;\r\n    }\r\n#endif\r\n\r\n    vec4 posProj \x3d proj * vec4(aux.posView, 1.0);\r\n\r\n#ifdef CENTER_OFFSET_UNITS_SCREEN\r\n\r\n#ifdef SCREEN_SIZE_PERSPECTIVE\r\n    float centerOffsetY \x3d applyScreenSizePerspectiveScaleFactorFloat(centerOffset.y, perspectiveFactor);\r\n#else\r\n    float centerOffsetY \x3d centerOffset.y;\r\n#endif\r\n\r\n    posProj.xy +\x3d vec2(centerOffset.x, centerOffsetY) * 2.0 / viewport.zw * posProj.w;\r\n\r\n#endif\r\n\r\n    // constant part of polygon offset emulation\r\n    posProj.z -\x3d groundRelative * polygonOffset * posProj.w;\r\n\r\n    return posProj;\r\n  }\r\n\r\n  /**\r\n   * Test for visibility of a HUD object.\r\n   *\r\n   * Dependencies:\r\n   *\r\n   *   Uniforms:\r\n   *     - hudVisibilityTexture: the texture that contains the visibility information\r\n   *     - markerColor: the special marker color that is used to write visibility information\r\n   *     - viewport: the viewport\r\n   */\r\n  bool testVisibilityHUD(vec4 posProj) {\r\n    // For occlusion testing, use the nearest pixel center to avoid\r\n    // subpixel filtering messing up the color we use to test for\r\n    vec4 posProjCenter \x3d alignToPixelCenter(posProj, viewport.zw);\r\n\r\n    return texture2D(hudVisibilityTexture, .5 + .5 * posProjCenter.xy / posProjCenter.w).r \x3e 0.0;\r\n  }\r\n]]\x3e\x3c/snippet\x3e\r\n\r\n\x3c/snippets\x3e\r\n'}});
define("dojo/text!./internal/util.xml dojo/text!./internal/hud.xml ./BillboardMaterial ./ColorMaterial ./HUDMaterial ./LineCalloutMaterial ./LeafCardMaterial ./Material ./RibbonLineMaterial ./WaterMaterial ./internal/SimpleGLMaterial ./internal/TexOnlyGLMaterial ./internal/BlendLayers".split(" "),function(e,f,g,h,k,l,m,n,p,q,r,t,u){return{initializeShaders:function(a,b,c,d){a._parse(e);a._parse(f);r.loadShaders(a,b,c,d);t.loadShaders(a,b,c,d);n.loadShaders(a,b,c,d);g.loadShaders(a,b,c,d);k.loadShaders(a,
b,c,d);l.loadShaders(a,b,c,d);m.loadShaders(a,b,c,d);p.loadShaders(a,b,c,d);q.loadShaders(a,b,c,d);u.loadShaders(a,b,c,d);h.loadShaders(a,b,c,d)}}});